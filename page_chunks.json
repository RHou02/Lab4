[
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p1",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 1,
    "text": "HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation Haoran Luo1,2, Haihong E1→, Guanting Chen1, Yandan Zheng2, Xiaobao Wu2, Yikai Guo3, Qika Lin4, Yu Feng5, Zemin Kuang6, Meina Song1, Yifan Zhu1, Luu Anh Tuan2 1Beijing University of Posts and Telecommunications 2Nanyang Technological University 3Beijing Institute of Computer Technology and Application 4National University of Singapore 5China Mobile Research Institute 6Beijing Anzhen Hospital, Capital Medical University haoran.luo@ieee.org, ehaihong@bupt.edu.cn, anhtuan.luu@ntu.edu.sg Abstract Standard Retrieval-Augmented Generation (RAG) relies on chunk-based retrieval, whereas GraphRAG advances this approach by graph-based knowledge representa- tion. However, existing graph-based RAG approaches are constrained by binary relations, as each edge in an ordinary graph connects only two entities, limiting their ability to represent the n-ary relations (n →2) in real-world knowledge. In this work, we propose HyperGraphRAG, the ﬁrst hypergraph-based RAG method that represents n-ary relational facts via hyperedges. HyperGraphRAG consists of a comprehensive pipeline, including knowledge hypergraph construction, retrieval, and generation. Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and pre- vious graph-based RAG methods in answer accuracy, retrieval efﬁciency, and generation quality. Our data and code are publicly available1. 1 Introduction v1 e 1 v2 v3 v5 v6 v7 v4 e 2 e 4 e 3 Knowledge HyperGraph N-ary Relation LLM User Question HyperGraph Retrieval LLM HyperGraph-Guided Generation Knowledgable Domain Knowledge Extraction Generation Figure 1: An illustration of HyperGraphRAG. Retrieval-Augmented Generation (RAG) [10, 6] has advanced knowledge-intensive tasks by inte- grating knowledge retrieval with large language models (LLMs) [17, 28], thereby enhancing fac- tual awareness and generation accuracy. Stan- dard RAG typically relies on chunk-based re- trieval, segmenting documents into ﬁxed-length text chunks retrieved via dense vector similarity, which overlooks the relationships between en- tities. Recently, GraphRAG [2] has emerged as a promising direction that structures knowledge as a graph to capture inter-entity relations, with the potential to improve retrieval efﬁciency and knowledge-driven generation [18]. However, since each edge in an ordinary graph connects only two entities, existing graph-based RAG approaches [2, 7, 1, 8] are all restricted to binary relations, making them insufﬁcient for modeling the n-ary relations among more than two entities that are widespread in real-world domain knowledge [25]. For example, in the medical domain, as illustrated in Figure 2, representing →Corresponding author. 1 https://github.com/LHRLAB/HyperGraphRAG 39th Conference on Neural Information Processing Systems (NeurIPS 2025). arXiv:2503.21322v3 [cs.AI] 21 Oct 2025"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p2",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 2,
    "text": "... Male hypertensive patients with serum creatinine levels between 115–133 μmol/L are diagnosed with mild serum creatinine elevation. ... Hypertensive patient Male Mild serum creatinine elevation Serum creatinine levels between 115–133 μmol/L Hyperedge_1 Male Hypertensive patient Serum creatinine levels between 115–133 μmol/L Mild serum creatinine elevation Hyperedge_3 Hyperedge_4 Hyperedge_2 Ordinary Graph Knowledge Representation Hypergraph-Structured Knowledge Representation ... ... Male hypertensive patients with serum creatinine levels between 115–133 μmol/L are diagnosed with mild serum creatinine elevation. ... ... ... ... Chunk-based Knowledge Representation Standard RAG GraphRAG HyperGraphRAG Domain Knowledge Figure 2: Comparison of knowledge representation: standard RAG uses chunks as units, GraphRAG captures binary relations with graphs, and HyperGraphRAG models n-ary relations with hyperedges. the fact that “Male hypertensive patients with serum creatinine levels between 115–133 µmol/L are diagnosed with mild serum creatinine elevation” requires decomposing it into several binary relational triples, such as Gender:(Hypertensive patient, Male) and Diagnosed_with:(Hypertensive patient, Mild serum creatinine elevation), leading to representation sparsity during conversion process. To address these limitations, we propose HyperGraphRAG, as illustrated in Figure 1, a novel graph- based RAG method built upon hypergraph-structured knowledge representation. In contrast to prior graph-based RAG methods constrained to binary relations, HyperGraphRAG leverages hyperedges to represent n-ary relational facts, where each hyperedge connects n entities (n →2), e.g. Hyperedge:(Hypertensive patient, Male, Serum creatinine levels between 115–133 µmol/L, Mild serum creatinine elevation), and each hyperedge is expressed through natural language descriptions. This design ensures knowledge completeness, structural expressiveness, and inferential capability, thereby providing more comprehensive support for knowledge-intensive applications. Our proposed HyperGraphRAG is built upon three key steps. First, we propose a knowledge hypergraph construction method, leveraging LLM-based n-ary relation extraction to extract and structure multi-entity relationships. The resulting hypergraph is stored in a bipartite graph database, with separate vector databases for entities and hyperedges to facilitate efﬁcient retrieval. Second, we develop a hypergraph retrieval strategy that employs vector similarity search to retrieve relevant entities and hyperedges, ensuring that the knowledge retrieved is both precise and contextually relevant. Lastly, we introduce a hypergraph-guided generation mechanism, which combines retrieved n-ary facts with traditional chunk-based RAG passages, thereby improving response quality. To validate the effectiveness, we conduct experiments in multiple knowledge-intensive domains [7], in- cluding medicine, agriculture, computer science, and law. Results demonstrate that HyperGraphRAG outperforms standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efﬁciency, and generation quality, showcasing its strong potential for real-world applications. 2 Related Work Graph-based RAG. GraphRAG [2] is the ﬁrst graph-based RAG method that improves LLM generation via graph-based retrieval. Based on GraphRAG, several methods [26, 22, 11, 4, 23] focus on building graph-based RAG for different applications. LightRAG [7] enhances efﬁciency via graph indexing and updates. PathRAG [1] and HippoRAG2 [8] reﬁne retrieval with path pruning and Personalized PageRank. However, all rely on binary relations, limiting knowledge expressiveness. In this work, we propose HyperGraphRAG, the ﬁrst graph-based RAG method via hypergraph-structured knowledge representation. We compare several existing methods with HyperGraphRAG in Table 1. Hypergraph Representation. Hypergraph-structured knowledge representation aims to overcome ordinary graph’s limitations in modeling n-ary relations [15]. Early methods [25, 27, 12, 21] employ various embedding techniques to represent n-ary relational entities. Later methods [5, 24, 14] utilize GNN or attention to enhance embedding. However, existing methods mainly focus on link prediction, while hypergraphs also show potential for enhancing knowledge representation in graph-based RAG. 2"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p3",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 3,
    "text": "Table 1: Comparison of knowledge construction and retrieval methods for NaiveGeneration, Stan- dardRAG, partial GraphRAG baselines, and our proposed HyperGraphRAG, where K represents the overall constructed knowledge, and K→ q represents retrieved knowledge when given a user question q. Method Knowledge Construction Knowledge Retrieval NaiveGeneration K = →. K→ q = →. StandardRAG K = {ci}N i=1, where ci is a chunk. K→ q = Kchunk = Topk{ c ↑K | sim(hq, hc) } GraphRAG [2] K = S = {sg | g ↑Community(G)}, where S is the community summary set. K→ q = Detect{sg ↑S | q}, where detected community summaries are retrieved. LightRAG [7] K = G = (V, E), where V & E are entity & relation sets. K→ q = F{v ↑V, e ↑E | q} ↓Kchunk, where entities & relations are retrieved with chunks. PathRAG [1] K = G = (V, E), where G is the same as LightRAG’s. K→ q = Prune{p ↑Pq | q}, where relational paths are retrieved via pruning. HippoRAG2 [8] K = G = (V ↓M, E), where V & M are phrase & passage nodes. K→ q = PageRank{m ↑M | q}, where passages are retrieved via Personalized PageRank. HyperGraphRAG (ours) K = GH = (V, EH), where GH is structured as a hypergraph. K→ q = Fn{v ↑V | q} ↓Fn{e ↑EH | q} ↓Kchunk, where n-ary relational facts are retrieved with chunks. 3 Preliminaries Deﬁnition 1: RAG. Given a question q and domain knowledge K, standard RAG ﬁrst selects relevant document fragments d from K based on q, and then generates an answer y based on q and d. The probability model is formulated as: P(y|q) = ! d↑K P(y|q, d)P(d|q, K). (1) Deﬁnition 2: Graph-based RAG. Graph-based RAG optimizes retrieval by representing knowledge as a graph structure G = (V, E), where V is the set of entities and E is the set of relationships between entities. G consists of facts represented as F = (e, Ve) ↑G, where e is the relation and Ve is the entity set connected to e. Given a question q, the retrieval process is deﬁned as: P(y|q) = ! F ↑G P(y|q, F)P(F|q, G). (2) Deﬁnition 3: Hypergraph. A hypergraph GH = (V, EH) [29] is a generalized graph, where V is the entity set, EH is the hyperedge set, and each hyperedge eH ↑EH connects 2 or more entities: VeH = (v1, v2, ..., vn), n →2. (3) Unlike ordinary graphs, where relationships are binary Ve = (vh, vt), hypergraphs model n-ary relational facts Fn = (eH, VeH) ↑GH. 4 Method: HyperGraphRAG In this section, we introduce the proposed HyperGraphRAG, as shown in Figure 3, including knowledge hypergraph construction, hypergraph retrieval strategy, and hypergraph-guided generation. 4.1 Knowledge Hypergraph Construction To represent and store knowledge, we propose a knowledge hypergraph construction method that includes n-ary relational extraction, bipartite hypergraph storage, and vector representation storage. N-ary Relation Extraction. To construct the knowledge hypergraph GH, our ﬁrst step is to extract multiple n-ary relational facts Fn from natural language documents d ↑K. Unlike traditional hyper-relations [21], events [13], or other n-ary relation models [15], in the era of LLMs, to preserve richer and more diverse n-ary relations among entities, we propose a new n-ary relation representation Fn = (eH, VeH), utilizing natural language descriptions, instead of structured relations, to represent hyperedges eH among multiple entities VeH as follows. (a) Hyperedge: Given an input text d, it is parsed into several independent knowledge fragments, each treated as a hyperedge: Ed H = {e1, e2, ..., ek}. Each hyperedge ei = (etext i , escore i ) consists of two parts: a natural language description etext i , and a conﬁdence score escore i ↑(0, 10] indicating the association degree between ei and d. 3"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p4",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 4,
    "text": "Hyperedge Retrieval N-ary relation extraction <hyperedge>(text:“Hypertension is defined as an office systolic blood pressure ≥140 mmHg or diastolic blood pressure ≥90 mmHg.”, score:“9”) - <entity>(name:“Hypertension”, type:“Disease”, explain:“Hypertension is defined as systolic blood pressure ≥140 mmHg or diastolic blood pressure ≥90 mmHg.”, score:“95”) - <entity>(name:“Systolic blood pressure ≥140 mmHg”, type:“Measurement”, explain:“Systolic blood pressure ≥140 mmHg falls within the definition of hypertension.”, score:“85”) - <entity>(name:“Diastolic blood pressure ≥90 mmHg”, type:“Measurement”, explain:“Diastolic blood pressure ≥90 mmHg falls within the definition of hypertension.”, score:“85”) N-ary Relational Facts ... Domain Knowledge Bipartite Hypergraph Storage Hyperedge Vector Base Entity Vector Base Hyperedge_3 Hyperedge_2 Hyperedge_4 Hyperedge_1 Systolic BP ≥140 mmHg Diastolic BP ≥90 mmHg Elevated BP Stroke Hypertension Cardiovascular Disease Low-sodium Diet Regular Exercise Stress Management Ejection Fraction BNP Heart Failure Knowledge HyperGraph Construction Domain Knowledge Knowledge HyperGraph Knowledge HyperGraph HyperGraph Retrieval HyperGraph-Guided Generation Knowledgable Generation Candidate Hyperedges & Entities User Question Input Output Extract Embedding Embedding How does hypertension affect cardiovasular health, and what interventions can effectively reduce its risk? User Question hypertension, cardiovasular health, ... Extracted Entities Entity Retrieval Hypertension Cardiovascular Disease ... Hyperedge_1 Hyperedge_2 ... HyperGraph Retrieval ... Retrieved N-ary Relational Facts Traditional Chunks Hybird Generation Hypertension is a major risk factor for... Knowledgable Generation Entity Extract Knowledge File LLM with Prompts Entity Hyperedge Vector Base N-ary Relational Facts Figure 3: An overview of HyperGraphRAG, which constructs a knowledge hypergraph from domain knowledge, retrieves n-ary facts based on user questions, and generates knowledgeable responses. (b) Entity: For each hyperedge ei, entity recognition is performed to extract all contained en- tities: Vei = {v1, v2, ..., vn}, where Vei is the entity set associated with ei. Each entity vj = (vname j , vtype j , vexplain j , vscore j ) consists of four parts: entity name vname j ↓etext i , type vtype j , explanation vexplain j , and conﬁdence score vscore j ↑(0, 100] indicating the extraction certainty. Following this hypergraph-structured knowledge representation, we design an n-ary relation extraction prompt pext, detailed in Appendix A.1, to enable the LLM ω to perform end-to-end knowledge fragment segmentation and entity recognition, thereby forming the n-ary relational fact set F d n: F d n = {f1, f2, ..., fk} ↔ω(Fn|pext, d), (4) where each extracted n-ary relational fact fi = (ei, Vei) contains information about the corresponding hyperedge ei and its associated entity set Vei. We convert all documents d ↑K into hyperedges and entities using n-ary relation extraction, forming a complete knowledge hypergraph GH. Proposition 1. Hypergraph-structured knowledge representation is more comprehensive than binary. Proof. We provide experimental results in Section 5.4 and proofs in Appendix B.1. Bipartite Hypergraph Storage. After n-ary relation extraction, we store the constructed knowledge hypergraph GH in a graph database to support an efﬁcient query. We adopt an ordinary graph database represented as a bipartite graph structure GB = (VB, EB) = !(GH), to store the knowledge hypergraph GH = (V, EH), where ! is a transformation function deﬁned as: ! : VB = V ↗EH, EB = {(eH, v) | eH ↑EH, v ↑VeH}, (5) where VB is the set of nodes in GB, formed by merging the entity set V and the hyperedge set EH from GH. The edge set EB captures the connections between each hyperedge eH ↑EH and its associated entities v ↑VeH. Based on GB, we can efﬁciently query all entities associated with a hyperedge eH or query all hyperedges linked to a speciﬁc entity v, thereby beneﬁting the optimized query efﬁciency of an ordinary graph database, as well as preserving the complete hypergraph-structured knowledge representation. Moreover, GB allows incremental updates through dynamically expansion: GB ↘GB ↗!(G↓ H), where G↓ H represents newly added hypergraph information. The transformation of hyperedges and entities into the bipartite graph storage format enables seamless updates to the graph database. Proposition 2. A bipartite graph can losslessly preserve and query a knowledge hypergraph. Proof. We provide proofs in Appendix B.2. 4"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p5",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 5,
    "text": "Vector Representation Storage. To support efﬁcient semantic retrieval, we embed hyperedges eH ↑ EH and entities v ↑V using the same embedding model f, ensuring that the vector representation of hyperedges and entities is in the same vector space as questions. Let ” be the vector function, then the vector representation storage for the knowledge hypergraph GH is deﬁned as: ”(GH) = (EH, EV ), where EH is the vector base of hyperedges and EV is the vector base of entities: ” : EH = {heH | eH ↑EH}, EV = {hv | v ↑V }, (6) where each hyperedge eH and entity v in GH is embedded into their vector representations: heH = f(eH), and hv = f(v), respectively. 4.2 Hypergraph Retrieval Strategy After constructing and storing the hypergraph GH, we design an efﬁcient retrieval strategy to match user questions with relevant hyperedges and entities. Entity Retrieval. First, we extract key entities from the question q to facilitate subsequent matching. We design an entity extraction prompt pq_ext, detailed in Appendix A.2, along with the LLM ω to extract the entity set Vq: Vq ↔ω(V |pq_ext, q). (7) After extracting entities, we retrieve the most relevant entities from the entity set V of the knowledge hypergraph GH. We deﬁne the entity retrieval function RV , which retrieves the most relevant entities from EV using cosine similarity: RV (q) = kV argmax v↑V \" sim(hVq, hv) ≃vscore# >ωV , (8) where hVq = f(Vq) is the concatenated text vector representation of the extracted entity set Vq, hv ↑EV is the vector representation of entity v, sim(·, ·) denotes the similarity function, ≃represents element-wise multiplication between similarity and entity relevance score vscore determining the ﬁnal ranking score, εV is the threshold for the entity retrieval score, and kV is the limit on the number of retrieved entities. Hyperedge Retrieval. Moreover, to expand the retrieval scope and capture complete n-ary relations within the hyperedge set EH of the knowledge hypergraph GH, we deﬁne the hyperedge retrieval function RH, which retrieves a set of hyperedges related to q: RH(q) = kH argmax eH↑EB (sim(hq, heH) ≃escore H )>ωH , (9) where hq = f(q) is the text vector representation of q, heH ↑EH is the vector representation of the hyperedge eH, ≃represents element-wise multiplication between similarity and hyperedge relevance score escore H determining the ﬁnal ranking score, εH is the threshold for the hyperedge retrieval score, and kH limits the number of retrieved hyperedges. 4.3 Hypergraph-Guided Generation To fully utilize the structured knowledge in the hypergraph, we propose a Hypergraph-Guided Generation mechanism, which consists of hypergraph knowledge fusion and generation augmentation. Hypergraph Knowledge Fusion. The primary goal of hypergraph knowledge fusion is to expand and reorganize the retrieved n-ary relational knowledge to form a comprehensive knowledge input. Since q may only match partial entities or hyperedges, we further expand the retrieval scope. To obtain a complete set of n-ary relational facts, we design a bidirectional expansion strategy, that includes expanding hyperedges from retrieved entities and expanding entities from retrieved hyperedges. First, given the entity set retrieved from q, denoted as RV (q) = {v1, v2, ..., vkV }, we retrieve all hyperedges in the knowledge hypergraph GH that connect these entities: F→ V = $ vi↑RV (q) {(eH, VeH) | vi ↑VeH, eH ↑EH}. (10) Next, we expand the set of entities connected to the retrieved hyperedges RH(q) = {e1, e2, ..., ekH}: F→ H = $ ei↑RH(q) {(ei, Vei) | Vei ↓V } (11) 5"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p6",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 6,
    "text": "Finally, we merge the expanded hyperedge set F→ V with the expanded entity set F→ H to form a complete retrieved n-ary relational fact set KH = F→ V ↗F→ H. This set contains all necessary n-ary relational knowledge for reasoning and generation, ensuring a comprehensive input for the LLM. Generation Augmentation. Following hypergraph knowledge fusion, we augment the generation strategy to improve the accuracy and readability of the responses. We adopt a hybrid RAG fusion mechanism, combining hypergraph knowledge KH with retrieved chunk-based text fragments Kchunk to form the ﬁnal knowledge input. We deﬁne the ﬁnal knowledge input K→= KH ↗Kchunk, where Kchunk consists of chunk-based text fragments retrieved using traditional RAG. Finally, we use a retrieval-augmented generation prompt pgen, detailed in Appendix A.3, that combines hypergraph knowledge K→and the user question q as input to LLM ω to generate ﬁnal response y→: y→↔ω(y|pgen, K→, q). (12) Proposition 3. Retrieving knowledge on a knowledge hypergraph improves retrieval efﬁciency compared to methods based on ordinary binary graphs, leading to gains in generation quality. Proof. We provide experimental results in Sections 5.5 and 5.6 and proofs in Appendix B.3. 5 Experiments This section presents the experimental setup, main results, and analysis. We answer the following research questions (RQs): RQ1: Does HyperGraphRAG outperform other methods? RQ2: Does the main component of HyperGraphRAG work? RQ3: How effective is the knowledge hypergraph con- structed by HyperGraphRAG across various domains? RQ4: Could the hypergraph retrieval strategy improve retrieval efﬁciency? RQ5: How effective is the generation quality of HyperGraphRAG? RQ6: How are the time and cost of HyperGraphRAG in construction and generation phases? 5.1 Experimental Setup Datasets. To evaluate the performance of HyperGraphRAG across multiple domains, we select four knowledge contexts from UltraDomain [19], as used in LightRAG [7]: Agriculture, Computer Science (CS), Legal, and a mixed domain (Mix). In addition, we include the latest international hypertension guidelines [16] as the foundational knowledge for the Medicine domain. For each of the ﬁve domains, we sample knowledge fragments one, two, and three hops away to construct questions with ground-truth answers veriﬁed by human annotators. We then categorize the questions into Binary Source and N-ary Source, based on whether the sampled knowledge of the question contains facts among n entities (n > 2). More details can be found in Appendix D. Baselines. We compare HyperGraphRAG against six publicly available baseline methods: Naive- Generation [17], which directly generates responses using LLM; StandardRAG [6], a traditional chunk-based RAG approach; GraphRAG [2], LightRAG [7], PathRAG [1], and HippoRAG2 [8], which are four selected available graph-based RAG methods described in Table 1. To ensure fairness, we use the same generation prompt, which can be found in Appendix E. Evaluation Metrics. We evaluate the answer accuracy, retrieval efﬁciency, and generation quality of HyperGraphRAG and its baselines using 3 key metrics: F1, Retrieval Similarity (R-S), and Generation Evaluation (G-E). F1 measures word-level similarity between the generated answer and the ground-truth answer, following FlashRAG [9]. R-S assesses the semantic similarity between the retrieved knowledge and the ground-truth knowledge used to construct the question, in line with RAGAS [3]. G-E, inspired by HelloBench [20], is a metric that uses LLM-as-a-judge to evaluate generation quality in 7 dimensions and reports the average score. Details are provided in Appendix E. Implementation Details. We use OpenAI’s GPT-4o-mini for extraction and generation, and text-embedding-3-small for vector. During retrieval, we set the following parameters: entity retrieval kV = 60, εV = 50; hyperedge retrieval kH = 60, εH = 5; and chunk retrieval kC = 5, εC = 0.5. All experiments were conducted on a server with an 80-core CPU and 512GB RAM. 5.2 Main Results (RQ1) To evaluate the effectiveness of HyperGraphRAG, we compare its performance with various baselines across multiple domains. The results are shown in Table 2. 6"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p7",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 7,
    "text": "Table 2: Performance comparison across different domains. Bold indicates the best performance. Method Medicine Agriculture CS Legal Mix F1 R-S G-E F1 R-S G-E F1 R-S G-E F1 R-S G-E F1 R-S G-E Binary Source NaiveGeneration 12.63 0.00 44.70 11.71 0.00 45.76 18.93 0.00 48.79 22.91 0.00 50.00 18.58 0.00 46.14 StandardRAG 26.87 61.08 56.24 28.31 42.69 57.58 28.87 49.44 57.10 37.19 52.21 59.85 47.57 46.79 67.42 GraphRAG 17.13 54.56 48.19 20.67 40.90 52.41 23.75 37.65 53.17 31.09 34.26 54.62 23.62 25.01 48.12 LightRAG 12.16 52.38 44.15 17.70 41.24 50.32 22.59 41.86 51.62 33.63 45.54 56.42 29.98 34.22 54.50 PathRAG 14.74 52.30 45.36 21.97 42.21 53.13 25.28 41.49 53.28 32.32 43.60 55.45 40.87 33.36 60.75 HippoRAG2 21.12 57.50 51.08 12.60 16.85 44.56 16.94 21.05 47.29 20.10 34.13 46.77 21.10 18.34 45.83 HyperGraphRAG (ours) 36.45 69.91 60.65 34.80 61.97 59.99 31.60 60.94 57.54 44.42 60.87 63.53 51.51 67.34 68.76 N-ary Source NaiveGeneration 13.15 0.00 41.83 13.78 0.00 47.93 18.37 0.00 48.94 20.37 0.00 48.09 15.29 0.00 45.16 StandardRAG 28.93 64.06 55.08 26.55 48.93 56.62 28.99 47.35 56.69 37.50 51.16 60.09 38.83 47.73 61.82 GraphRAG 18.07 57.22 47.09 21.90 41.27 53.49 22.90 39.97 53.76 29.12 34.11 53.76 14.93 24.32 42.32 LightRAG 13.43 54.67 41.86 18.78 42.44 50.92 22.85 41.19 52.20 29.64 44.47 54.65 24.08 33.22 50.83 PathRAG 15.14 54.08 42.77 20.64 42.53 51.83 28.18 42.29 54.97 30.27 44.47 55.26 33.27 34.11 57.47 HippoRAG2 21.56 61.54 48.06 12.66 20.32 45.14 17.75 26.92 48.44 16.95 34.72 45.09 21.95 18.49 46.87 HyperGraphRAG (ours) 34.26 70.48 58.06 32.98 62.58 59.59 31.00 59.25 58.35 43.20 60.07 63.70 45.91 69.09 65.04 Overall NaiveGeneration 12.89 0.00 43.27 12.74 0.00 46.85 18.65 0.00 48.87 21.64 0.00 49.05 16.93 0.00 45.65 StandardRAG 27.90 62.57 55.66 27.43 45.81 57.10 28.93 48.40 56.89 37.34 51.68 59.97 43.20 47.26 64.62 GraphRAG 17.60 55.89 47.64 21.28 41.08 52.95 23.33 38.81 53.47 30.11 34.18 54.19 19.27 24.67 45.22 LightRAG 12.79 53.52 43.00 18.24 41.84 50.62 22.72 41.53 51.91 31.64 45.00 55.53 27.03 33.72 52.67 PathRAG 14.94 53.19 44.06 21.30 42.37 52.48 26.73 41.89 54.13 31.29 44.03 55.36 37.07 33.73 59.11 HippoRAG2 21.34 59.52 49.57 12.63 18.58 44.85 17.34 23.99 47.87 18.53 34.42 45.93 21.53 18.42 46.35 HyperGraphRAG (ours) 35.35 70.19 59.35 33.89 62.27 59.79 31.30 60.09 57.94 43.81 60.47 63.61 48.71 68.21 66.90 Overall Comparison Across Methods. HyperGraphRAG consistently outperforms all baselines across F1, R-S, and G-E metrics. Compared to StandardRAG, it achieves gains of +7.45 (F1), +7.62 (R-S), and +3.69 (G-E). Interestingly, existing graph-based RAG baselines often underperform StandardRAG, as their reliance on binary relational graphs causes knowledge fragmentation, sparsiﬁed retrieval, and incomplete context reconstruction during generation. Comparison Across Source Types. HyperGraphRAG maintains strong gains under both Binary and N-ary settings. For Binary Source, it improves F1, R-S, and G-E by +8.6, +8.8, and +4.4; for N-ary Source, the improvements are +5.3, +6.4, and +2.9, conﬁrming its robustness. Comparison Across Domains. Performance gains are consistent across domains, with the largest improvements in Medicine and Legal (over +7 F1), and stable advantages in Agriculture and CS. HyperGraphRAG adapts well to both highly structured and more general knowledge tasks. 5.3 Ablation Study (RQ2) As shown in Figure 4, we conduct an ablation study in the Medicine domain by removing entity retrieval (w/o ER), hyperedge retrieval (w/o HR), and their combination (w/o ER & HR). We also remove chunk retrieval fusion (w/o CR), and all modules (w/o ER & HR & CR): Figure 4: Results of the ablation study. Impact of Entity Retrieval (ER). ER is crit- ical for precise retrieval by anchoring key con- cepts. Without ER, F1 falls from 35.4 to 29.8, underscoring its importance in selecting relevant entities for accurate generation. Impact of Hyperedge Retrieval (HR). HR captures n-ary, multi-entity facts necessary for complex reasoning. Removing HR drops F1 from 35.4 to 26.4, highlighting its unique role beyond mere entity retrieval. Impact of Chunk Retrieval Fusion (CR). CR enhances retrieval by integrating unstructured text with hypergraph data. Excluding CR reduces F1 from 35.4 to 29.2, demonstrating that the fusion leads to more complete and ﬂuent generation. 7"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p8",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 8,
    "text": "5.4 Analysis of Hypergraph-structured Knowledge Representation (RQ3) As shown in Figure 5, we assess HyperGraphRAG’s knowledge representation across 5 domains: (a) Medicine HyperGraph (b) Agriculture HyperGraph (c) CS HyperGraph (d) Legal HyperGraph (e) Mix HyperGraph Med. Agric. CS Legal Mix #Knowl. Token 179k 382k 795k 940k 122k GraphRAG #Entity 329 699 1449 1711 225 #Community 256 523 930 517 59 LightRAG #Entity 3,725 5,032 8,967 5,354 2,229 #Relation 1,304 3,105 5,632 6,002 940 HyperGraphRAG #Entity 7,675 16,805 19,913 11,098 6,201 #Hyperedge 4,818 16,102 26,902 18,285 4,356 (f) Statistics of Construction Figure 5: (a-e) Visualizations of knowledge hypergraphs constructed in 5 domains. (f) Statistical comparison highlights HyperGraphRAG’s richer expressiveness over GraphRAG and LightRAG. Visualization of Knowledge Structures. As shown in Figure 5(a)-5(e), unlike previous graph-based RAG methods, which only model binary relations, HyperGraphRAG connects multiple entities via hyperedges, forming a more interconnected and expressive network. Statistical Analysis. As shown in Figure 5(f), HyperGraphRAG surpasses GraphRAG and LightRAG in all domains. For instance, in CS, it constructs 26,902 hyperedges, whereas GraphRAG has 930 communities and LightRAG 5,632 relations, showing a stronger capacity for capturing knowledge. 5.5 Analysis of Hypergraph Retrieval Efﬁciency (RQ4) As shown in Figure 6, to evaluate retrieval efﬁciency, we conduct two experiments: (a) examining how HyperGraphRAG’s retrieval efﬁciency and token length scales with different top-k values and (b) comparing its F1 scores with other methods under varying retrieval length limits: (a) Impact of Top-k on Retreval Efﬁcency & Token Length. (b) F1 Comparison under Limited Lengths. Figure 6: Experimental results in the Medicine domain analyzing hypergraph retrieval efﬁciency. Impact of Retrieved Hyperedge Quantity. As shown in Figure 6(a), increasing the top-k hyperedges improves F1, R-S, and G-E, along with the rise in token count. Performance saturates around k = 60, indicating that HyperGraphRAG achieves strong retrieval quality with limited input. Performance under Constrained Retrieval Length. As illustrated in Figure 6(b), HyperGraphRAG outperforms all binary graph-based RAG methods even under retrieval length limits, demonstrating the efﬁciency of n-ary representations and highlighting the semantic loss inherent in binary structures. 8"
  },
  {
    "chunk_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf::p9",
    "doc_id": "HyperGraphRAG- Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation.pdf",
    "page_num": 9,
    "text": "5.6 Analysis of Hypergraph-Guided Generation Quality (RQ5) As shown in Figure 7, we evaluate the quality of the generation in seven dimensions: Figure 7: Generation Equality Evaluations. Best Overall Generation Quality. Hyper- GraphRAG achieves the highest Overall score (61.5), signiﬁcantly outperforming all baseline methods, indicating the comprehensive advan- tage in hypergraph-guided generation. Lead on Key Dimensions. HyperGraphRAG achieves notable improvements in Correctness (64.8), Relevance (66.0), and Factuality (64.2), outperforming both standard RAG and binary graph-based methods. These gains indicate its strong capacity to produce accurate, context- aware, and knowledge-grounded responses. Balanced Performance. Although the Diver- sity score (47.0) is relatively lower than other dimensions, HyperGraphRAG still exceeds all baselines, indicating that it maintains a balanced dimension-wise performance, effectively com- bining content richness with structural consis- tency for stable and high-quality generation. 5.7 Analysis of Time and Cost in Construction and Generation Phases (RQ6) As shown in Table 3, to evaluate the efﬁciency and cost of HyperGraphRAG, we compare different methods in terms of knowledge construction and generation. We assess time consumption per 1k tokens (TP1kT), cost per 1k tokens (CP1kT), time per query (TPQ), and cost per 1k query (CP1kQ). Table 3: Time & Cost Comparisons. Method Construction Generation TP1kT CP1kT TPQ CP1kQ NaiveGeneration 0 s 0 $ 0.131 s 0.059 $ StandardRAG 0 s 0 $ 0.147 s 1.016 $ GraphRAG 9.272 s 0.0058 $ 0.221 s 1.836 $ LightRAG 5.168 s 0.0081 $ 0.359 s 3.359 $ PathRAG 5.168 s 0.0081 $ 0.436 s 3.496 $ HippoRAG2 2.758 s 0.0056 $ 0.240 s 3.438 $ HyperGraphRAG 3.084 s 0.0063 $ 0.256 s 3.184 $ Time & Cost in Construction Phase. Hyper- GraphRAG demonstrates efﬁcient knowledge construction with a time cost of 3.084 sec- onds per 1k tokens (TP1kT) and a monetary cost of $0.0063 per 1k tokens (CP1kT). This places it between the faster HippoRAG2 (2.758s, $0.0056) and slower GraphRAG (9.272s, $0.0058). While its cost is slightly higher than GraphRAG, HyperGraphRAG achieves a bet- ter balance between speed, expressiveness, and structure, offering a more compact yet richer representation of n-ary relational knowledge. Time & Cost in Generation Phase. During the generation phase, HyperGraphRAG requires 0.256 seconds per query (TPQ) and incurs a cost of $3.184 per 1k queries (CP1kQ). This is moderately higher than StandardRAG (0.147s, $1.016) but signiﬁcantly lower than PathRAG (0.436s, $3.496) and LightRAG (0.359s, $3.359). Compared to GraphRAG (0.221s, $1.836), HyperGraphRAG slightly increases time and cost but compensates with better retrieval quality and generation outcomes. The results suggest that HyperGraphRAG achieves a favorable trade-off between generation efﬁciency and output quality, suitable for real-world knowledge-intensive applications. 6 Conclusion In this work, we present HyperGraphRAG, a retrieval-augmented generation framework that models knowledge as hypergraphs to capture n-ary relational structures. By introducing novel methods for knowledge hypergraph construction, retrieval, and generation, HyperGraphRAG addresses limitations of binary graph-based RAG methods. Experimental results across diverse domains demonstrate consistent improvements in answer accuracy, retrieval relevance, and generation quality, conﬁrming the effectiveness and generalizability of hypergraph-guided retrieval and generation. 9"
  },
  {
    "chunk_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf::p1",
    "doc_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf",
    "page_num": 1,
    "text": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics 1st Rajeev Kumar Gen AI Research Althire AI San Francisco, USA rajeev@althire.ai 2nd Kumar Ishan Gen AI Research Althire AI Bangaluru, India ishan@althire.ai 3rd Harishankar Kumar Gen AI Research Althire AI Gurgaon, India hsk@althire.ai 4th Abhinandan Singla Gen AI Research Althire AI Gurgaon, India abhinandan@althire.ai Abstract—Disconnected data silos within enterprises obstruct the extraction of actionable insights, diminishing efficiency in areas such as product development, client engagement, meeting preparation, and analytics-driven decision-making. This paper in- troduces a framework that uses large language models (LLMs) to unify various data sources into a comprehensive, activity-centric knowledge graph. The framework automates tasks such as entity extraction, relationship inference, and semantic enrichment, en- abling advanced querying, reasoning, and analytics across data types like emails, calendars, chats, documents, and logs. Designed for enterprise flexibility, it supports applications such as contex- tual search, task prioritization, expertise discovery, personalized recommendations, and advanced analytics to identify trends and actionable insights. Experimental results demonstrate its success in the discovery of expertise, task management, and data-driven decision making. By integrating LLMs with knowledge graphs, this solution bridges disconnected systems and delivers intelligent analytics-powered enterprise tools. Index Terms—Knowledge graph, Entity extraction, Relation extraction, LLM, Activity Graph, Enterprise Intelligence. I. INTRODUCTION Today, companies face the challenge of disconnected data ecosystems, where critical information resides in silos such as emails, calendars, documents, activity logs, and other reposito- ries. Although these data sets are rich in content, the absence of a unified semantic representation hinders meaningful insights and reduces efficiency in workflows such as task prioritization, client engagement, meeting preparation, and analytics-driven decision-making. Lack of integration limits the ability to derive trends, perform predictive analytics, or uncover actionable insights essential for informed decision-making and strate- gic planning. Unified knowledge graphs have emerged as a promising solution, offering the ability to model relationships between disparate data facets and allowing cohesive reasoning and representation [1],[2]. However, existing approaches often depend on rigid ontologies and system-specific implementa- tions, making them difficult to scale and adapt to the diverse and dynamic needs of modern enterprises. The primary motivation behind this work is to unify dis- parate data silos to improve enterprise workflows and decision- making. We introduce a single, user-centric knowledge graph that integrates multiple sources (emails, calendars, chats, documents, and logs) through LLM-driven entity extraction, relationship inference, and semantic enrichment. Our system- agnostic design avoids rigid ontologies, offering enhanced an- alytics for tasks such as expertise discovery, task prioritization, and anomaly detection, all while maintaining scalability and flexibility across diverse enterprise contexts. This paper presents a novel framework for constructing and querying LLM-powered user-centric activity knowledge graphs. LLMs excel in semantic enrichment, entity extraction, and contextual reasoning, making them ideal for creating dynamic and adaptive graph structures [2]. By integrating diverse data sources, including emails, calendars, chats, logs, and documents, the framework creates a unified representa- tion centered on user activities and organizational objectives. Beyond traditional applications, the framework supports ad- vanced analytics by allowing the discovery of trends, patterns, and relationships that would otherwise remain hidden. This ca- pability is particularly valuable for predictive decision making, anomaly detection, and workflow optimization. Applications range from contextual search, task prioritization, and expertise discovery to personalized recommendations and advanced data analytics tailored to organizational needs [3]-[5]. Experimental results demonstrate its effectiveness in improving workflows such as aggregating daily priorities, preparing for meetings, and conducting analytics-driven assessments, while also seam- lessly adapting to new data and domains [4],[6]. This framework employs LLMs to dynamically infer re- lationships, enriching knowledge graphs with unrecognized connections and analytical context. It supports multimodal data integration—including textual, temporal, and behavioral data—allowing comprehensive reasoning, trend analysis, and advanced query capabilities. The user-centric design of the framework further ensures accessibility through natural lan- guage interfaces. For example, questions such as “What are my key priorities this week?” or “What trends are emerging in client engagement?” produce aggregated insights from disparate systems, providing intuitive solutions to complex enterprise challenges. By bridging the gap between fragmented data silos and analytics-powered enterprise intelligence, this work offers a scalable and adaptive approach for modern orga- nizations to extract actionable insights and improve decision- 979-8-3315-2480-7/25/$31.00 ©2025 IEEE arXiv:2503.07993v1 [cs.AI] 11 Mar 2025"
  },
  {
    "chunk_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf::p2",
    "doc_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf",
    "page_num": 2,
    "text": "making. II. LITERATURE REVIEW The integration of Large Language Models (LLMs) and knowledge graphs has gained significant attention to address fragmented enterprise data silos and enhance intelligent deci- sion making. Knowledge graphs have long been recognized for their ability to represent complex relationships in diverse data domains, allowing contextual reasoning and semantic enrichment [2]. However, traditional approaches often rely on static ontologies, limiting adaptability to dynamic en- terprise workflows. Recent advances in LLM, particularly their capabilities in entity extraction, relation inference, and contextual understanding, have further expanded the potential of knowledge graphs [1]-[2]. Several studies highlight the application of LLMs in en- terprise settings, such as task prioritization, analytics-driven insights, and expertise discovery [3]. These works emphasize the value of combining LLM with retrieval-augmented gen- eration (RAG) techniques to enhance precision in contextual retrieval and entity-relationship extraction. In addition, appli- cations such as contextual search and task alignment have demonstrated the ability to improve productivity and decision making by bridging data silos [6]. Although prior efforts have largely focused on specific domains or static datasets, this paper extends the literature by presenting a dynamic, system- agnostic framework capable of adapting to evolving enterprise needs, providing actionable insights, and addressing real-world challenges such as meeting preparation, task management, and expertise identification. Despite these promising directions, there are notable chal- lenges and limitations when integrating LLM and knowledge graphs in enterprise contexts. One key concern is hallucination, where LLMs can generate inaccurate facts or relationships, necessitating robust validation mechanisms. Data privacy and security are also of great importance, particularly when en- terprise data is sensitive or subject to regulatory constraints. The computational overhead of running LLM-based extraction at scale can be prohibitive, requiring careful optimization and hardware considerations. Finally, ontology mismatch can arise when merging different knowledge sources or when domain- specific ontologies conflict, highlighting the need for adaptive schema alignment and continuous ontology evolution [7]- [9]. These challenges underscore the importance of designing frameworks that not only leverage the strengths of LLMs, but also implement safeguards to maintain data integrity, scalability, and compliance. III. METHODOLOGY Our proposed framework is designed to unify multifaceted data into a single knowledge graph, seamlessly connecting information from emails, meetings, tasks, documents, and other sources. It is built with several key objectives in mind: system agnosticism, scalability, extensibility, and intelligent query processing. The framework achieves these objectives through a robust architecture that enables data ingestion, graph construction, efficient storage, and natural language querying. Using large language models (LLMs), the framework auto- mates entity extraction, relationship inference, and contextual enrichment, ensuring a dynamic and adaptive knowledge graph structure that scales across domains. At the core of the framework lies a unified graph rep- resentation, where nodes represent entities such as people, topics, or events, and edges represent relationships inferred by LLMs. This graph structure dynamically updates as new data is ingested, making it adaptable to evolving data environments. Inspired by advances in the integration of LLMs with knowl- edge graphs [6]-[15], the framework employs five primary components: a data ingestion layer, a graph construction mod- ule, a distributed graph store, a query interface and scenario- specific extensions. Fig. 1 explains the top-level architecture of this framework. Fig. 1. Framework overview for unified knowledge graph A. Dataset Explanation The data set for this experimentation was collected from consulting companies operating in various domains, includ- ing power, medicine, finance, gaming, and more, which en- compasses a wide range of expertise and services. These companies not only provide consulting, but also engage in product development, covering nearly all major industries. Their operations are heavily driven by client meetings, task prioritization, and identifying the right personnel to execute specific projects, often under the challenge of high employee turnover rates. Data were anonymized by removing identifiable informa- tion and sensitive content, ensuring compliance with privacy standards. All data were voluntarily shared by employees, contributing to a rich dataset of more than 3 million activities generated over the last two years. This data set provides a com- prehensive view of consulting workflows, including meetings, task management, and resource allocation, making it ideal for studying patterns and improving operational efficiency."
  },
  {
    "chunk_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf::p3",
    "doc_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf",
    "page_num": 3,
    "text": "B. Extraction And Summarizer This layer collects raw data from sources such as emails, calendars, documents, customer interactions, activity logs, social media feeds, and public knowledge bases. Data retrieval is managed through APIs or crawlers, with secure permissions and access tokens. Modular extensions allow plugins for specific data types, such as email synchronization, calendar events, and document indexing, to operate at configurable intervals with opt-in or opt-out controls. To address data sensitivity, especially for emails and documents, the frame- work ensures secure operations in private cloud environments. Only summary-level metadata essential for graph construction is extracted, balancing robust data integration with privacy compliance. 1) Content Extractor: The Context Extractor is a prepro- cessing component that gathers all relevant textual and visual content from emails, meetings, tasks, and communications to prepare data for the SmartSummarizer. Extracts and consoli- dates information such as email bodies, attachments, calendar descriptions, task details, and associated images, ensuring that all contextual elements required to generate meaningful summaries are captured. The component filters unnecessary or redundant data and focuses on collecting only the input content relevant to preserving entities, activities, and relationships. This ensures that the SmartSummarizer runs efficiently with complete and high-quality contextual input. 2) Smart-Summarizer: The Smart-Summarizer is an LLM- powered module designed to generate concise, structured summaries while ensuring that all relevant entities, activities, and relationships are preserved in the summary text. Rather than explicitly extracting entities or relationships, the module focuses on maintaining their integrity within the generated summary, ensuring contextual completeness and relevance. It also filters out sensitive information, such as unique identifiers or private details, to ensure downstream components process only de-identified and privacy-compliant text. This approach balances rich content representation with security and compli- ance requirements, enabling seamless downstream integration. Fig. 2. Explains with an example. For example, the Smart-Summarizer processes email datasets to extract key details such as the sender, recipient, subject, and timestamps, along with embedded information like event specifics, hotel bookings, or flight details. Similarly, meeting invitations or document attachments are summarized to capture topics and relationships, including references from external links or associated files. Calendar entries are analyzed to extract participants, locations, and schedules, while LLMs infer connections, such as associating an email referencing ”Project A” with a related calendar meeting. Once the sum- maries are enriched with these details, the data is refined and prepared for integration into the graph construction module. C. Entity-Relationship Extraction The Smart-Summarizer output is processed by this layer, which performs Named Entity Extraction (e.g., names, lo- cations, dates) and Relation Extraction (e.g., traveling on, Fig. 2. LLM-powered Smart-Summarizer converting input text, attached documents, and images into concise, structured summaries. staying at, attending event, participating in). This component identifies key entities and relationships, using a contextual rel- evance module to retrieve pertinent information about entities from the existing knowledge graph (KG) store. This enriched context enhances the precision of LLMs based extraction. The workflow begins with contextual retrieval, followed by entity extraction and relationship extraction, ensuring an accurate mapping of interactions. At this stage, entities are not yet linked to real-world counterparts, and relationships remain unnormalized with respect to the ontology defined in the framework. 1) Contextual Retrieval: he Contextual Retrieval Mod- ule (CRM) employs Retrieval-Augmented Generation (RAG) techniques to enhance a given summary by retrieving addi- tional information about related entities and their relationships from the Knowledge Graph (KG). By integrating relevant entity summaries and associated relations, the CRM provides enriched context to ensure greater precision in downstream entity and relationship extraction tasks. This added context enables a more comprehensive understanding of interactions and supports better decision making. Fig. 3. is an example of contextual information extracted for summarized text from KG through RAG. 2) Entity Extraction: The entity extraction process is a critical step in converting summarized content, enriched with additional contextual information, into structured data. This component leverages Large Language Models (LLMs) with carefully designed prompt engineering techniques, augmented by contextual data retrieved from the Contextual Retrieval Module (CRM). Using in-context learning, the process im- proves the precision and consistency of entity extraction,"
  },
  {
    "chunk_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf::p4",
    "doc_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf",
    "page_num": 4,
    "text": "Fig. 3. Contextual Retrieval Module Extracting Entity and Relationship Insights from the Knowledge Graph effectively resolving ambiguities and improving downstream workflows. Experiments without contextual enrichment, such as using basic prompts or a few-shot examples, demonstrated sub- optimal results compared to the use of enriched contextual information. The integration of CRM-provided context signif- icantly outperformed other methods, yielding more accurate and reliable entity extraction. This approach ensures a compre- hensive list of extracted entities, providing a solid foundation for subsequent tasks. 3) Relation Extraction: The relationship extraction process is a vital step in structuring the interactions between entities identified in the summarized content, further enriched with contextual information. This component utilizes LLMs with advanced prompt engineering techniques, incorporating both contextual data retrieved from the CRM and the extracted entities as input. Using these enriched inputs, the process enhances the precision and relevance of relationship extraction, effectively resolving ambiguities and providing meaningful connections between entities. D. Real-time Graph Construction The graph construction module is responsible for resolving entity ambiguities and assigning unique identifiers to maintain consistency across the knowledge graph. Recognized entities are matched to their existing identifiers, while new identifiers are assigned to previously unknown entities. Relationships and attributes are aligned with a pre-existing ontology schema, or a new schema is generated when necessary. All data is nor- malized to adhere to the specified ontology format, ensuring semantic compatibility throughout the graph. Each identified entity is represented as a node, with relationships inferred by the LLMs depicted as edges. For instance, a calendar meeting is represented as a meeting node connected to participant nodes, with edges labeled with properties such as ”attends” or ”organizes.” Contextual enrichment is incorporated, enabling LLMs to infer additional relationships, such as connecting a project mentioned in a document to a related task, resulting in a more connected and enriched data structure. As illustrated in Fig. 4, this process begins with transform- ing extracted entities and relationships into vector embeddings via embedding models. Simultaneously, existing entities and Fig. 4. Leveraging Embedding Models, Contextual Retrieval, and LLM- Based Mapping to Construct Graph Triples for Knowledge Graphs. relationships within the graph database undergo the same embedding process, with their vector representations stored in a vector store for efficient retrieval. The vector store facilitates the retrieval of relevant entities and relationships from the knowledge graph that align with the extracted data. The extracted candidates and entities are processed by the LLM- based entity matching module, which resolves ambiguities and accurately maps the extracted entities to existing graph entities. Following this, the LLM-based relationship mapping module integrates the matched entities with the ontology schema to infer and normalize relationships, ensuring that they align with domain-specific semantics. The resulting output is a set of graph triples representing entities, relationships, and associated contextual information, which are stored in the graph database for subsequent queries and reasoning tasks. E. Recommendations and Analytics Layer The Recommendations and Analytics layer combines knowledge graph data with LLM-based reasoning to provide actionable insights and analytics. Designed to meet diverse enterprise needs, this layer supports applications such as meet- ing preparation, task prioritization, expertise identification, and analytics-driven decision making. Customized LLM prompts with contextual learning are tailored for each scenario to achieve optimal results. Although the following sections detail three key applications, the system is currently being tested"
  },
  {
    "chunk_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf::p5",
    "doc_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf",
    "page_num": 5,
    "text": "for more than five use cases, highlighting its versatility and potential for broader implementation. 1) Expertise Discovery: This layer enables users to iden- tify employees with expertise in specific skills, concepts, or topics by analyzing their contributions to tasks, meetings, and communications. It is particularly valuable for fostering col- laboration and streamlining task delegation. Users can upload entire discussion threads or related documents to the system, which processes the input to generate a list of domain experts. Leveraging LLMs, the system extracts and ranks skills or concepts connected to the input text, performs graph traversal on the knowledge graph, and refines results using LLM-based re-ranking to ensure precision and relevance. For example, when a user queries ”Who is the best person to consult about influencer marketing strategies?” the system navigates the knowledge graph to identify individuals linked to ”influencer marketing” through documented skills, completed projects, or participation in relevant meetings. The ranked results might highlight individuals like Sarah Lee, a market- ing strategist with notable contributions to recent campaigns. Similarly, for conversation-based queries like ”Who has been involved in discussions about AI model optimization?” the system analyzes conversation logs, extracts contextual details, and cross-references the knowledge graph to identify and rank experts. This functionality reduces the time it takes to locate appropriate resources and promotes more effective collaboration between teams. 2) Task Prioritization: In this system, the knowledge graph is constructed with the user as a central node, enabling the sys- tem to understand all user-specific activities. By traversing the graph, the system provides daily or weekly recommendations on which tasks should be prioritized. In addition, it displays relevant materials, conversations, or contextual information that is needed to perform those tasks efficiently. The dynamic nature of this system ensures that any changes in priorities, such as leadership-level decisions, are immediately reflected, often before managers have the opportunity to communicate these changes. This capability significantly improves employ- ees’ ability to stay up-to-date and focus on high-priority tasks, streamlining the prioritization process, and improving overall productivity. 3) Insights and Decision-Making: The system leverages graph analytics and LLMs to process natural language queries, translating them into graph traversal and analytics operations. Retrieval of relevant statistics from the knowledge graph, segmentation of data as needed, and refinement of results for clarity and precision. For instance, a query like ”What per- centage of tasks were completed on time last quarter?” would retrieve task-completion rates, segmented by departments. The response might state: ”In Q3, 75% of the tasks were completed on time, with the marketing team achieving 85% and the engineering team achieving 65%. This functionality provides decision makers with actionable insights tailored to their needs, facilitating data-driven de- cisions that improve performance and address inefficiencies. By providing detailed analytics in an accessible format, the system enables organizations to optimize workflows, identify bottlenecks, and align strategies with operational goals. F. System Evaluation We conducted a 6-month pilot study in two large com- panies in the finance and healthcare sectors to validate the performance of the system in real world environments. During this deployment period, our framework integrated diverse data sources, such as emails, internal chats, and project documents, while supporting workflows such as expertise discovery and task prioritization. To quantitatively assess performance, we used a combination of metrics tailored to specific function- alities, including NDCG (Normalized Discounted Cumulative Gain) for rank-based tasks and additional indicators such as user satisfaction rates, precision and recall. This approach allowed us to capture both short-term and long-term impacts of the system. The feedback of the employees highlighted benefits such as centralized knowledge access and improved task alignment, underscoring the utility and scalability of the framework in daily operations. For expertise discovery, we measured the system’s expert ranking using NDCG, supplemented by user feedback to vali- date recommendations. Additional metrics like Mean Recipro- cal Rank (MRR) helped gauge the precision of the top-ranked results. For task prioritization, the system recommended tasks based on importance, urgency, and dependencies, and we tracked user actions (e.g., task completions) to infer implicit relevance signals. The precision at k (P @ k), the recall, and NDCG were then used to assess how effectively the system prioritized critical tasks. In analytics queries, user satisfaction served as the key metric: For example, when asked ’What percentage of tasks were completed on time last quarter?’, the system retrieved statistics from the knowledge graph, refined them via LLM, and provided actionable insights. In addition, the performance of different LLM models was assessed for the extraction of entities and relationships, as well as application-level services. Comparative experiments demonstrated that integrating contextual data from the knowl- edge graph improved extraction accuracy and downstream task performance. This multifaceted evaluation framework ensured a comprehensive understanding of the system’s capabilities and its impact on enterprise workflows. IV. RESULTS AND DISCUSSION The evaluation results, summarized in Tables I, II, and III, demonstrate the effectiveness of the system in various functionalities, with metrics such as precision, recall, NDCG, and satisfaction rates that highlight its impact on enterprise applications. In addition to scenario evaluations, internal com- ponents were evaluated, with entity extraction achieving 92% accuracy and relationship extraction reaching 89%, supported by contextual enrichment that improved task alignment by 15%. During a six-month period, the system achieved a user adoption rate 78% across multiple departments and success- fully addressed five of the six targeted scenarios, including expertise discovery, task prioritization, and analytics. These"
  },
  {
    "chunk_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf::p6",
    "doc_id": "LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics.pdf",
    "page_num": 6,
    "text": "results underscore the system’s ability to enhance workflows and deliver actionable insights. TABLE I EXPERTISE DISCOVERY PERFORMANCE Metric Description Performance NDCG Evaluates the ranking quality of sug- gested experts based on relevance scores from follow-up feedback. NDCG@5=0.80, NDCG@3=0.63 MPR Measures how quickly the most rele- vant expert appears in the ranked list MPR=0.83 Precision at K Assesses the relevance of the top-k recommended experts P@3=0.62, P@5=0.83. TABLE II TASK PRIORITIZATION PERFORMANCE Metric Description Performance NDCG Evaluates the prioritzation of tasks based on user implicit feedback. NDCG@5=0.72, NDCG@3=0.59 Precision at K Measures how accurately top-k rec- ommended tasks align with completed tasks P@3=0.57, P@5=0.80. Recall Measures how many critical tasks were included in recommendations. Recall=0.83. TABLE III ANALYTICAL QUERIES PERFORMANCE Metric Description Performance Satisfaction Rate Assesses user satisfaction with analyt- ical insights delivered by the system. 83% positive feed- back Accuracy Compares system-generated analytics to manual calculations. Accuracy = 0.86. The results highlight the effectiveness of integrating LLM with knowledge graphs in addressing enterprise challenges, demonstrating significant improvements in task prioritization, expertise discovery, and analytics-driven decision making. V. CONCLUSIONS This paper presents a novel framework that integrates Large Language Models (LLMs) with knowledge graphs to address key enterprise challenges, including expertise discovery, task prioritization, and analytics-driven decision-making. Using contextual retrieval and advanced entity-relationship extrac- tion techniques, the system dynamically generates actionable insights, personalized recommendations, and precise analytics. The evaluation results demonstrate high performance in met- rics such as NDCG, precision, recall, and user satisfaction, with notable improvements in prioritization accuracy and expert identification. This framework improves productivity, collaboration, and decision-making in enterprise environments, bridges fragmented data silos, and enables intelligent, scalable solutions tailored to dynamic organizational needs. Future work will expand the system’s applications and further refine its scalability and adaptability. VI. FUTURE WORK In the future, we plan to enrich the knowledge graph with multimodal data, including images and audio, to provide more comprehensive visual and auditory signals. We will also fine-tune LLM models for specific tasks to achieve higher performance metrics and explore real-time collaboration fea- tures, such as linking internal entities to external knowledge graphs (e.g., Wikipedia) for deeper insights. This could help organizations understand the impact of external events on task priorities or identify large-scale opportunities. Furthermore, scaling the system for larger datasets and incorporating ad- vanced predictive analytics will enhance decision making by forecasting potential risks, recommending proactive measures, or automatically spotting emerging trends. Finally, expanding the framework to domains such as risk assessment, compliance monitoring, and personalized employee training will broaden its utility and impact in diverse enterprise workflows. REFERENCES [1] Bommasani, R., Hudson, D., Adcock, A., et al. (2021). On the oppor- tunities and risks of foundation models. [2] Ji, S., Pan, S., Cambria, E., et al. (2022). A survey on knowledge graphs: Representation, construction, and applications. IEEE Transactions on Neural Networks and Learning Systems. [3] Guo, Y., Gao, H., Li, J., Pan, J. (2022). Conversational query graphs for intuitive knowledge navigation. International Journal of Semantic Computing. [4] Wang, Q., Mao, Z., Wang, B., Guo, L. (2022). Knowledge graph embedding: A survey of approaches and applications. IEEE Transactions on Big Data. [5] Zhang, Y., Liu, J., Wang, F., et al. (2021). Task prioritization in multi- faceted knowledge graphs. In Proceedings of the 27th ACM SIGKDD Conference. [6] Ibrahim, N., Aboulela, S., Ibrahim, A., Kashef, R. (2024). A survey on augmenting knowledge graphs (KGs) with large language models (LLMs): Models, evaluation metrics, benchmarks, and challenges. Dis- cover Artificial Intelligence, 4(76). Springer. DOI: 10.1007/s44163-024- 00175-8. [7] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X. (2024). Unifying large language models and knowledge graphs: A roadmap. arXiv preprint arXiv:2306.08302. [8] Jin, B., Liu, G., Han, C., Jiang, M., Ji, H., Han, J. (2024). Large language models on graphs: A comprehensive survey. arXiv preprint arXiv:2312.02783. [9] Agrawal, G., Kumarage, T., Alghamdi, Z., Liu, H. (2023). Can knowl- edge graphs reduce hallucinations in LLMs? A survey. arXiv preprint arXiv:2311.07914. [10] Khorashadizadeh, H., Amara, F. Z., Ezzabady, M., Ieng, F., Tiwari, S., Mihindukulasooriya, N., Groppe, J., Sahri, S., Benamara, F., Groppe, S. (2024). Research trends for the interplay between large language models and knowledge graphs. arXiv preprint arXiv:2406.08223. [11] Chen, Z., Zhang, N., Chen, H. (2024). Knowledge graphs meet multi-modal learning: A comprehensive survey. arXiv preprint arXiv:2402.05391. [12] Li, H., Appleby, G., Suh, A. (2024). A preliminary roadmap for LLMs as assistants in exploring, analyzing, and visualizing knowledge graphs. arXiv preprint arXiv:2404.01425. [13] He, X. (2024). Awesome-Graph-LLM. GitHub Repository. https://github.com/XiaoxinHe/Awesome-Graph-LLM. [14] Luo, R. (2024). Awesome-LLM-KG: Awesome papers about unifying LLMs and KGs. GitHub Repository. https://github.com/RManLuo/Awesome-LLM-KG. [15] UpcomAI. (2024). KG-LLMs-papers: A repository for knowl- edge graph and large language model papers. GitHub Repository. https://github.com/UpcomAI/KG-LLMs-papers."
  }
]